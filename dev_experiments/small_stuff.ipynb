{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIT et méthodes\n",
    "Le petit code suivant, montre que les méthodes même si elles sont associées à des instances différentes, sont liées dans leur compilations et le fait de récréer la classe réinitialise les compilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "[1. 1.]\n",
      "1 1 1\n",
      "[2. 2.]\n",
      "1 1 1\n",
      "[-1. -1.]\n",
      "2 2 2\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "from jax import jit, clear_caches\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "class Class(eqx.Module):\n",
    "    att1: jnp.ndarray\n",
    "    att2: str = eqx.field(static=True)\n",
    "\n",
    "    def meth(self):\n",
    "        if self.att2 == 'r':\n",
    "            return self.att1\n",
    "        else:\n",
    "            return -self.att1\n",
    "    \n",
    "    @jit\n",
    "    def jit_meth(self, **kwargs):\n",
    "        return self.meth(**kwargs)\n",
    "    jit_met = jit(meth)\n",
    "\n",
    "insr = Class(jnp.ones(2), 'r')\n",
    "insr2 = Class(2*jnp.ones(2), 'r')\n",
    "insd = Class(jnp.ones(2), 'd')\n",
    "\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr2.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insd.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "clear_caches()\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "[1. 1.]\n",
      "1 1 1\n",
      "[2. 2.]\n",
      "1 1 1\n",
      "[-1. -1.]\n",
      "2 2 2\n"
     ]
    }
   ],
   "source": [
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr2.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insd.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 1.]\n",
      "1 1\n",
      "[2. 2.]\n",
      "1 1 1\n",
      "[-1. -1.]\n",
      "2 2 2\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "class Class(eqx.Module):\n",
    "    att1: jnp.ndarray\n",
    "    att2: str = eqx.field(static=True)\n",
    "\n",
    "    def meth(self):\n",
    "        if self.att2 == 'r':\n",
    "            return self.att1\n",
    "        else:\n",
    "            return -self.att1\n",
    "    \n",
    "    @jit\n",
    "    def jit_meth(self, **kwargs):\n",
    "        return self.meth(**kwargs)\n",
    "    jit_met = jit(meth)\n",
    "\n",
    "\n",
    "insr = Class(jnp.ones(2), 'r')\n",
    "print(insr.jit_meth._cache_size())\n",
    "print(insr.jit_meth())\n",
    "insr2 = Class(2*jnp.ones(2), 'r')\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size())\n",
    "print(insr2.jit_meth())\n",
    "insd = Class(jnp.ones(2), 'd')\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insd.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "même une instantce qui vient d'être créee hérite d'une version compilée des méthodes -> c'est sympa merci jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# si l'attribut est une fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "[1. 1.]\n",
      "1 1 1\n",
      "[2. 2.]\n",
      "2 2 2\n",
      "[-1. -1.]\n",
      "3 3 3\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "from jax import jit, clear_caches\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from typing import Callable\n",
    "\n",
    "class Class(eqx.Module):\n",
    "    att1: jnp.ndarray\n",
    "    att2: Callable[[float], float] = eqx.field(static=True)\n",
    "\n",
    "    def meth(self):\n",
    "        return self.att2(self.att1)\n",
    "    \n",
    "    @jit\n",
    "    def jit_meth(self):\n",
    "        return self.meth()\n",
    "\n",
    "insr = Class(jnp.ones(2), lambda x: x)\n",
    "insr2 = Class(2*jnp.ones(2), lambda x: x)\n",
    "insd = Class(jnp.ones(2), lambda x: -x)\n",
    "\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr2.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insd.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "clear_caches()\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "[1. 1.]\n",
      "1 1 1\n",
      "[2. 2.]\n",
      "1 1 1\n",
      "[-1. -1.]\n",
      "2 2 2\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "from jax import jit, clear_caches\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from typing import Callable\n",
    "\n",
    "class Class(eqx.Module):\n",
    "    att1: jnp.ndarray\n",
    "    att2: Callable[[float], float] = eqx.field(static=True)\n",
    "\n",
    "    def meth(self):\n",
    "        return self.att2(self.att1)\n",
    "    \n",
    "    @jit\n",
    "    def jit_meth(self):\n",
    "        return self.meth()\n",
    "fun1 = lambda x: x\n",
    "fun2 = lambda x: -x\n",
    "\n",
    "insr = Class(jnp.ones(2), fun1)\n",
    "insr2 = Class(2*jnp.ones(2), fun1)\n",
    "insd = Class(jnp.ones(2), fun2)\n",
    "\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insr2.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "print(insd.jit_meth())\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n",
    "clear_caches()\n",
    "print(insr.jit_meth._cache_size(), insr2.jit_meth._cache_size(), insd.jit_meth._cache_size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apparamment il faut que la fonction soit associée au même nom de variable, si la fonction est égale dans le sens qu'elle fait la même chose, même pour une fonction très simple, ça ne marche pas. Ce n'est pas le même fonctionnement que pour les autres objets, genre les entiers ça va comparer les valeurs par exemple.Ça implique que si on veut ne pas recompiler sur des fonctions, ils faut que les fonctions soient définient le plus \"extérieurement\" possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recompilation avec le gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, clear_caches, grad\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from typing import Callable\n",
    "\n",
    "class Model(eqx.Module):\n",
    "    arr: jnp.ndarray\n",
    "    sign: str = eqx.field(static=True)\n",
    "\n",
    "    def run(self, par: float) -> jnp.ndarray:\n",
    "        if self.sign == 'pos':\n",
    "            return par*self.arr\n",
    "        elif self.sign == 'neg':\n",
    "            return -par*self.arr\n",
    "        else:\n",
    "            return 0.*self.arr\n",
    "\n",
    "def agreg(out: jnp.ndarray) -> float:\n",
    "    return jnp.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "(Array(2., dtype=float32, weak_type=True),)\n",
      "1 0\n",
      "(Array(2., dtype=float32), Model(arr=f32[2], sign='pos'))\n",
      "1 1\n",
      "(Array(4., dtype=float32, weak_type=True),)\n",
      "1 1\n",
      "(Array(-2., dtype=float32, weak_type=True),)\n",
      "2 1\n",
      "(Array(0., dtype=float32, weak_type=True),)\n",
      "3 1\n",
      "(Array(0., dtype=float32), Model(arr=f32[2], sign='qzeriough'))\n",
      "3 2\n"
     ]
    }
   ],
   "source": [
    "def loss_global(model: Model, par: float):\n",
    "    return agreg(model.run(par))\n",
    "\n",
    "jit_grad_loss_global = jit(grad(loss_global, argnums=(1,)))\n",
    "jit_filter_loss_global = jit(eqx.filter_value_and_grad(loss_global))\n",
    "\n",
    "model_pos = Model(jnp.ones(2), 'pos')\n",
    "model_pos2 = Model(2*jnp.ones(2), 'pos')\n",
    "model_neg = Model(jnp.ones(2), 'neg')\n",
    "model_other = Model(jnp.ones(2), 'qzeriough')\n",
    "\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_grad_loss_global(model_pos, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_filter_loss_global(model_pos, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_grad_loss_global(model_pos2, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_grad_loss_global(model_neg, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_grad_loss_global(model_other, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())\n",
    "print(jit_filter_loss_global(model_other, 1.))\n",
    "print(jit_grad_loss_global._cache_size(), jit_filter_loss_global._cache_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette première version, on fait une fonction loss qui prend en argument le modèle et les paramètres, et on dérive seulement par rapport aux paramètre. On constate sans grande surprise qu'il y a compilation à chaque fois que des nouvelles valeurs statiques sont utilisées pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2.0\n",
      "1\n",
      "1 0\n",
      "2.0\n",
      "1 0\n",
      "2.0\n",
      "1 1\n",
      "1 1 0\n",
      "4.0\n",
      "1 1 1\n",
      "1 1 1 0\n",
      "-2.0\n",
      "1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "clear_caches()\n",
    "def loss_generate(model: Model) -> Callable[[float], float]:\n",
    "    def loss(par: float) -> float:\n",
    "        return agreg(model.run(par))\n",
    "    return loss\n",
    "\n",
    "model_pos = Model(jnp.ones(2), 'pos')\n",
    "model_pos2 = Model(2*jnp.ones(2), 'pos')\n",
    "model_neg = Model(jnp.ones(2), 'neg')\n",
    "model_other = Model(jnp.ones(2), 'qzeriough')\n",
    "\n",
    "loss_model_pos = jit(grad(loss_generate(model_pos)))\n",
    "print(loss_model_pos._cache_size())\n",
    "print(loss_model_pos(1.))\n",
    "print(loss_model_pos._cache_size())\n",
    "loss_model_pos_bis = jit(grad(loss_generate(model_pos)))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size())\n",
    "print(loss_model_pos(1.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size())\n",
    "print(loss_model_pos_bis(1.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size())\n",
    "loss_model_pos2 = jit(grad(loss_generate(model_pos2)))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size())\n",
    "print(loss_model_pos2(2.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size())\n",
    "loss_model_neg = jit(grad(loss_generate(model_neg)))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_neg(2.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette deuxième version, on fait une fonction qui génère une fonction de coût à partir d'un modèle. On constate que la fonction générée ne se compile au plus qu'une fois ce qui est logique. Cependant on constate que lorsqu'on créé deux fois une fonction de coût avec le même modèle, la compilation n'est pas comptée en double et il y a de nouveau une compilation. Donc si j'utilise ça il faut être attentif à ce que les fonctions coût ne soient crées qu'une fois pour minimiser le nombre de compilations. On constate qu'il y a aussi compilation si seules les valeurs traçables de l'objet ne sont pas les mêmes, c'est donc très innefficace. Ça n'a pas le même compoterment du tout que les méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "2.0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "2.0\n",
      "1 0 0 0\n",
      "2.0\n",
      "1 1 0 0\n",
      "1 1 0 0\n",
      "8.0\n",
      "1 1 1 0\n",
      "1 1 1 0\n",
      "-4.0\n",
      "1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "clear_caches()\n",
    "\n",
    "model_pos = Model(jnp.ones(2), 'pos')\n",
    "model_pos2 = Model(2*jnp.ones(2), 'pos')\n",
    "model_neg = Model(jnp.ones(2), 'neg')\n",
    "\n",
    "@jit\n",
    "def loss_model_pos(par: float) -> float:\n",
    "    return agreg(model_pos.run(par))\n",
    "\n",
    "@jit\n",
    "def loss_model_pos_bis(par: float) -> float:\n",
    "    return agreg(model_pos.run(par))\n",
    "\n",
    "@jit\n",
    "def loss_model_pos2(par: float) -> float:\n",
    "    return agreg(model_pos2.run(par))\n",
    "\n",
    "@jit\n",
    "def loss_model_neg(par: float) -> float:\n",
    "    return agreg(model_neg.run(par))\n",
    "\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos(1.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos(1.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos_bis(1.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos2(2.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())\n",
    "print(loss_model_neg(2.))\n",
    "print(loss_model_pos._cache_size(), loss_model_pos_bis._cache_size(), loss_model_pos2._cache_size(), loss_model_neg._cache_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on fait comme précédemment mais on créé à la main les différentes fonctions coût liées aux différents objets. Mais on a le même résultat : trop de recompilation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tunax-HJdEmRAT-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
